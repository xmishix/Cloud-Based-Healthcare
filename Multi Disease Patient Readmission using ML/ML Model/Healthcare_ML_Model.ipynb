{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xd6EOe6BNby",
        "outputId": "6481b176-77c4-4ddd-fd2b-4633b4794791"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORT LIBRARIES"
      ],
      "metadata": {
        "id": "-lUezlYFFKUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
        "from sklearn.metrics import (roc_auc_score, average_precision_score, accuracy_score,\n",
        "                             precision_score, recall_score, f1_score, confusion_matrix,\n",
        "                             classification_report, roc_curve, precision_recall_curve)\n",
        "import joblib\n",
        "import math\n",
        "import time\n",
        "import json\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "WuEQ2T2-Eu1e"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import xgboost as xgb\n",
        "    XGBOOST_AVAILABLE = True\n",
        "except Exception:\n",
        "    XGBOOST_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    import shap\n",
        "    SHAP_AVAILABLE = True\n",
        "except Exception:\n",
        "    SHAP_AVAILABLE = False\n"
      ],
      "metadata": {
        "id": "6s06RdVyE7xY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOAD DATA"
      ],
      "metadata": {
        "id": "yd0y0SMJFUX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"/content/drive/MyDrive/final_dataset_realistic 1.csv\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/readmission_output.csv\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.2\n",
        "CV_FOLDS = 3\n",
        "N_JOBS = -1\n",
        "SCORING_METRIC = \"roc_auc\"\n",
        "RISK_THRESHOLD = 0.5"
      ],
      "metadata": {
        "id": "zzuGQuaZFXX1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_target_col(df):\n",
        "    \"\"\"Find a readmission-like target column name in dataframe.\"\"\"\n",
        "    candidates = [c for c in df.columns if any(k in c.lower() for k in ['readmit','readmission','readmitted','readmit_30','readmission_30'])]\n",
        "    return candidates[0] if candidates else None\n",
        "\n",
        "def remove_existing_risk_cols(df):\n",
        "    risk_cols = [c for c in df.columns if 'risk' in c.lower()]\n",
        "    if risk_cols:\n",
        "        print(\"Removing existing risk columns:\", risk_cols)\n",
        "        df = df.drop(columns=risk_cols, errors='ignore')\n",
        "    return df\n",
        "\n",
        "def safe_to_numeric(s):\n",
        "    try:\n",
        "        return pd.to_numeric(s, errors='coerce')\n",
        "    except Exception:\n",
        "        return s"
      ],
      "metadata": {
        "id": "INwAvVYuFzje"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOAD & CLEAN"
      ],
      "metadata": {
        "id": "OD4xVIYoF6J8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading data from:\", DATA_PATH)\n",
        "df_raw = pd.read_csv(DATA_PATH, dtype=object)\n",
        "print(\"Initial shape:\", df_raw.shape)\n",
        "df_raw = remove_existing_risk_cols(df_raw)\n",
        "\n",
        "# Detect target\n",
        "target_col = find_target_col(df_raw)\n",
        "if target_col is None:\n",
        "    raise RuntimeError(\"No readmission target column found. Please include a column name containing 'readmit' or 'readmission'.\")\n",
        "\n",
        "print(\"Detected target column:\", target_col)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwQleiSdF8fv",
        "outputId": "f2761e8e-dfcb-4468-9c0e-a1372fe04f60"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from: /content/drive/MyDrive/final_dataset_realistic 1.csv\n",
            "Initial shape: (5000, 37)\n",
            "Detected target column: Readmission\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJW-yCuHyJ7u",
        "outputId": "0efac4f4-d46b-408a-893e-bdd9117485ff"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Patient Name', 'Admission ID', 'Age', 'Sex', 'Weight',\n",
              "       'Admission Date', 'Admission Time', 'Consultant Doctor Name',\n",
              "       'Doctor Name', 'Doctor ID', 'Problem Type', 'Discharge Date',\n",
              "       'Discharge Time', 'Readmission', 'Blood Pressure', 'Insulin',\n",
              "       'Blood Group', 'Cholesterol', 'Platelets', 'Diabetics',\n",
              "       'Problem Description', 'Nurse Name', 'Patient Phone Number',\n",
              "       'Patient Mail ID', 'weather', 'air_quality_index', 'social_event_count',\n",
              "       'Hemoglobin (g/dL)', 'WBC Count (10^9/L)', 'Platelet Count (10^9/L)',\n",
              "       'Urine Protein (mg/dL)', 'Urine Glucose (mg/dL)', 'ECG Result',\n",
              "       'Pulse Rate (bpm)', 'State', 'City', 'Location'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NORMALIZE THE VALUES"
      ],
      "metadata": {
        "id": "x4sn3EUGGDPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_raw.copy()\n",
        "df[target_col] = df[target_col].astype(str).str.strip().str.lower().map({\n",
        "    'yes':'1','y':'1','true':'1','1':'1','no':'0','n':'0','false':'0','0':'0'\n",
        "})\n",
        "df[target_col] = pd.to_numeric(df[target_col], errors='coerce')\n",
        "print(\"Target value counts (including NaN):\")\n",
        "print(df[target_col].value_counts(dropna=False).to_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0717dLroF-RX",
        "outputId": "10db9119-58cd-46f9-e2c6-ac7e55412ac6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target value counts (including NaN):\n",
            "Readmission\n",
            "0    3212\n",
            "1    1788\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DROP ROWS WITH MISSING VALUES"
      ],
      "metadata": {
        "id": "ODUhsSF6GOde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "before = len(df)\n",
        "df = df[df[target_col].notna()].copy()\n",
        "print(f\"Dropped {before - len(df)} rows with missing target. Remaining: {len(df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKNz5H1lGL2_",
        "outputId": "4e9465db-831b-4a2a-90d9-10c1a5386298"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dropped 0 rows with missing target. Remaining: 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPLORATORY DATA ANALYTICS"
      ],
      "metadata": {
        "id": "dUXkkedTGZ7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Basic EDA ---\")\n",
        "print(\"Columns:\", list(df.columns))\n",
        "print(\"\\nNumeric sample summary (attempt coercion):\")\n",
        "# attempt to coerce commonly numeric columns for summary\n",
        "sample_numeric_cols = []\n",
        "for c in df.columns:\n",
        "    coerced = pd.to_numeric(df[c], errors='coerce')\n",
        "    if coerced.notna().sum() > max(10, 0.01 * len(df)):  # if column has many numeric-like values\n",
        "        sample_numeric_cols.append(c)\n",
        "print(\"Numeric-candidate columns:\", sample_numeric_cols[:20])\n",
        "if 'age' in [c.lower() for c in df.columns]:\n",
        "    ac = [c for c in df.columns if c.lower()=='age'][0]\n",
        "    print(df[ac].astype(str).describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJLQ0s-cGYWH",
        "outputId": "91932721-e56b-4d15-8248-143449ce278e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Basic EDA ---\n",
            "Columns: ['Patient Name', 'Admission ID', 'Age', 'Sex', 'Weight', 'Admission Date', 'Admission Time', 'Consultant Doctor Name', 'Doctor Name', 'Doctor ID', 'Problem Type', 'Discharge Date', 'Discharge Time', 'Readmission', 'Blood Pressure', 'Insulin', 'Blood Group', 'Cholesterol', 'Platelets', 'Diabetics', 'Problem Description', 'Nurse Name', 'Patient Phone Number', 'Patient Mail ID', 'weather', 'air_quality_index', 'social_event_count', 'Hemoglobin (g/dL)', 'WBC Count (10^9/L)', 'Platelet Count (10^9/L)', 'Urine Protein (mg/dL)', 'Urine Glucose (mg/dL)', 'ECG Result', 'Pulse Rate (bpm)', 'State', 'City', 'Location']\n",
            "\n",
            "Numeric sample summary (attempt coercion):\n",
            "Numeric-candidate columns: ['Age', 'Weight', 'Readmission', 'Cholesterol', 'Platelets', 'air_quality_index', 'social_event_count', 'Hemoglobin (g/dL)', 'WBC Count (10^9/L)', 'Platelet Count (10^9/L)', 'Urine Protein (mg/dL)', 'Urine Glucose (mg/dL)', 'Pulse Rate (bpm)']\n",
            "count     5000\n",
            "unique      72\n",
            "top         34\n",
            "freq        89\n",
            "Name: Age, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def quick_plots(df_local, target):\n",
        "    try:\n",
        "        sns.set()\n",
        "        plt.figure(figsize=(5,3))\n",
        "        sns.countplot(x=target, data=df_local)\n",
        "        plt.title(\"Target distribution\")\n",
        "        plt.show()\n",
        "    except Exception as e:\n",
        "        print(\"Skipping quick_plots due to:\", e)"
      ],
      "metadata": {
        "id": "kptGwdaeGkvT"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Feature engineering ---\")\n",
        "df_fe = df.copy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfdGfgRhGoPy",
        "outputId": "8750042f-1cb1-41c7-dbb3-58609eb3e674"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Feature engineering ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols_lower = {c.lower(): c for c in df_fe.columns}"
      ],
      "metadata": {
        "id": "7AS2lQUEGoKA"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "age_col = None\n",
        "for candidate in ['age','patient_age','age_years']:\n",
        "    if candidate in cols_lower:\n",
        "        age_col = cols_lower[candidate]\n",
        "        break\n",
        "\n",
        "if age_col:\n",
        "    df_fe[age_col] = pd.to_numeric(df_fe[age_col], errors='coerce')\n",
        "    df_fe['age_bucket'] = pd.cut(df_fe[age_col], bins=[0,30,50,65,80,200], labels=['<=30','31-50','51-65','66-80','80+'])\n",
        "    print(\"Created age_bucket from\", age_col)\n",
        "else:\n",
        "    print(\"No age column found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaMnykbsGvu0",
        "outputId": "ddf6a662-1e3a-4cba-84a2-016c71097392"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created age_bucket from Age\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "admit_col = None\n",
        "discharge_col = None\n",
        "for c in df_fe.columns:\n",
        "    low = c.lower()\n",
        "    if 'admit' in low and admit_col is None:\n",
        "        admit_col = c\n",
        "    if 'discharg' in low and discharge_col is None:\n",
        "        discharge_col = c\n",
        "\n",
        "if admit_col:\n",
        "    df_fe[admit_col] = pd.to_datetime(df_fe[admit_col], errors='coerce')\n",
        "if discharge_col:\n",
        "    df_fe[discharge_col] = pd.to_datetime(df_fe[discharge_col], errors='coerce')\n",
        "\n",
        "if admit_col and discharge_col:\n",
        "    df_fe['los_days'] = (df_fe[discharge_col] - df_fe[admit_col]).dt.days\n",
        "    df_fe.loc[(df_fe['los_days'] < 0) | (df_fe['los_days'] > 3650), 'los_days'] = np.nan\n",
        "    print(\"Computed los_days from\", admit_col, \"and\", discharge_col)\n",
        "else:\n",
        "    print(\"Admission/discharge dates not both found -> skipping LOS feature.\")\n",
        "\n",
        "# Comorbidity columns detection and count\n",
        "comorbidity_keywords = ['diabetes','hypertension','hyperten','cancer','copd','asthma','heart','renal','kidney','stroke']\n",
        "comorb_cols = [c for c in df_fe.columns if any(k in c.lower() for k in comorbidity_keywords)]\n",
        "print(\"Detected comorbidity-like columns:\", comorb_cols[:20])\n",
        "for c in comorb_cols:\n",
        "    df_fe[c] = pd.to_numeric(df_fe[c], errors='coerce').fillna(df_fe[c].astype(str).str.lower().map({'yes':1,'y':1,'true':1,'1':1,'no':0,'n':0,'false':0}))\n",
        "    df_fe[c] = pd.to_numeric(df_fe[c], errors='coerce').fillna(0).astype(int)\n",
        "if comorb_cols:\n",
        "    df_fe['comorbidity_count'] = df_fe[comorb_cols].sum(axis=1)\n",
        "else:\n",
        "    df_fe['comorbidity_count'] = 0\n",
        "\n",
        "# Date-based features (admit weekday/month)\n",
        "if admit_col:\n",
        "    df_fe['admit_weekday'] = df_fe[admit_col].dt.weekday\n",
        "    df_fe['admit_month'] = df_fe[admit_col].dt.month\n",
        "\n",
        "# Coerce some lab-like columns to numeric if present\n",
        "lab_keywords = ['hemoglobin','hb','wbc','platelet','creatinine','cholesterol','glucose','pulse']\n",
        "for c in df_fe.columns:\n",
        "    if any(k in c.lower() for k in lab_keywords):\n",
        "        df_fe[c] = pd.to_numeric(df_fe[c], errors='coerce')\n",
        "\n",
        "# Drop personal-identifying or long-text columns\n",
        "drop_candidates = [c for c in df_fe.columns if any(k in c.lower() for k in ['name','address','phone','mail','email','notes','description','image','photo','url'])]\n",
        "if drop_candidates:\n",
        "    print(\"Dropping candidate PII / long-text columns (count={}): {}\".format(len(drop_candidates), drop_candidates[:10]))\n",
        "    df_fe = df_fe.drop(columns=drop_candidates, errors='ignore')\n",
        "\n",
        "print(\"Feature engineering completed. Shape:\", df_fe.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRfCiO7_G5Mx",
        "outputId": "26bad67f-6f11-47e4-d9d5-18559cac7bf6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Admission/discharge dates not both found -> skipping LOS feature.\n",
            "Detected comorbidity-like columns: []\n",
            "Dropping candidate PII / long-text columns (count=7): ['Patient Name', 'Consultant Doctor Name', 'Doctor Name', 'Problem Description', 'Nurse Name', 'Patient Phone Number', 'Patient Mail ID']\n",
            "Feature engineering completed. Shape: (5000, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREPARE FEATURE MATRIX"
      ],
      "metadata": {
        "id": "3QaPCyLEHInJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nPreparing feature matrix X and target y...\")\n",
        "# Ensure target is int\n",
        "df_fe[target_col] = df_fe[target_col].astype(int)\n",
        "X = df_fe.drop(columns=[target_col], errors='ignore')\n",
        "y = df_fe[target_col]\n",
        "\n",
        "# Identify numeric and categorical features\n",
        "numeric_cols = X.select_dtypes(include=['int64','float64']).columns.tolist()\n",
        "# Treat small-cardinality object columns as categorical\n",
        "cat_cols = [c for c in X.columns if (X[c].dtype == object or X[c].nunique() < 50) and c not in numeric_cols]\n",
        "\n",
        "# Remove columns that are obviously datetime objects from feature lists\n",
        "numeric_cols = [c for c in numeric_cols if not np.issubdtype(type(X[c].dtype), np.datetime64)]\n",
        "# Make sure we don't include admit/discharge date columns directly\n",
        "for dtcol in [admit_col, discharge_col]:\n",
        "    if dtcol in cat_cols: cat_cols.remove(dtcol)\n",
        "    if dtcol in numeric_cols: numeric_cols.remove(dtcol)\n",
        "\n",
        "print(\"Numeric cols count:\", len(numeric_cols))\n",
        "print(\"Categorical cols count:\", len(cat_cols))\n",
        "\n",
        "# Preprocessor\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', numeric_transformer, numeric_cols),\n",
        "    ('cat', categorical_transformer, cat_cols)\n",
        "], remainder='drop', sparse_threshold=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eORIP4-VHQcG",
        "outputId": "151c81f3-2d3e-4834-903d-abacf973d54d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Preparing feature matrix X and target y...\n",
            "Numeric cols count: 9\n",
            "Categorical cols count: 21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SPLIT"
      ],
      "metadata": {
        "id": "561AV55qHZad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTrain/test split (test_size={})\".format(TEST_SIZE))\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE,\n",
        "                                                    random_state=RANDOM_STATE, stratify=y)\n",
        "print(\"Train size:\", X_train.shape, \"Test size:\", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlWDqD5PHbbc",
        "outputId": "109da0a8-2d88-4972-b12c-57726611c5d9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train/test split (test_size=0.2)\n",
            "Train size: (4000, 31) Test size: (1000, 31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL TRAINING & HYPER TUNING"
      ],
      "metadata": {
        "id": "7NSPIy7lHgmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "\n",
        "def evaluate_pipeline(name, pipeline, X_test, y_test):\n",
        "    y_prob = pipeline.predict_proba(X_test)[:,1]\n",
        "    y_pred = (y_prob >= RISK_THRESHOLD).astype(int)\n",
        "    metrics = {}\n",
        "    metrics['roc_auc'] = roc_auc_score(y_test, y_prob)\n",
        "    metrics['pr_auc']  = average_precision_score(y_test, y_prob)\n",
        "    metrics['accuracy'] = accuracy_score(y_test, y_pred)\n",
        "    metrics['precision'] = precision_score(y_test, y_pred, zero_division=0)\n",
        "    metrics['recall'] = recall_score(y_test, y_pred, zero_division=0)\n",
        "    metrics['f1'] = f1_score(y_test, y_pred, zero_division=0)\n",
        "    metrics['confusion_matrix'] = confusion_matrix(y_test, y_pred)\n",
        "    print(f\"\\n{name} Evaluation:\")\n",
        "    print(f\"ROC-AUC: {metrics['roc_auc']:.4f} | PR-AUC: {metrics['pr_auc']:.4f} | Acc: {metrics['accuracy']:.4f} | F1: {metrics['f1']:.4f}\")\n",
        "    print(\"Confusion matrix:\\n\", metrics['confusion_matrix'])\n",
        "    print(\"Classification report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "MPns63jcHkQt"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING OF DIABETICS AND THE HEART FAILURE"
      ],
      "metadata": {
        "id": "cHglUZIUJyR0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efd7ae33",
        "outputId": "7cae62c7-182e-4d8e-be67-937ac79d19a6"
      },
      "source": [
        "# ============================================================\n",
        "# Train 3 Models for Patient Readmission:\n",
        "#   - Logistic Regression\n",
        "#   - Random Forest\n",
        "#   - XGBoost\n",
        "# Separately for:\n",
        "#   - Diabetes\n",
        "#   - Heart Failure\n",
        "# Saves:\n",
        "#   - readmission_diabetes_RandomForest.pkl\n",
        "#   - readmission_heart_failure_RandomForest.pkl\n",
        "# ============================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier # Correctly import XGBClassifier\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, f1_score, precision_score,\n",
        "    recall_score, roc_auc_score, classification_report\n",
        ")\n",
        "\n",
        "# ============== CONFIG ==============\n",
        "# Use the DATA_PATH variable defined earlier in the notebook\n",
        "# DATA_PATH = \"final_dataset_realistic 1.csv\"  # adjust if needed\n",
        "RANDOM_STATE = 42\n",
        "N_SPLITS = 5\n",
        "TEST_SIZE = 0.2\n",
        "\n",
        "# ============== LOAD DATA ==============\n",
        "# Use the DATA_PATH variable to load the data\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "if \"Problem Type\" not in df.columns:\n",
        "    raise ValueError(\"Dataset must contain 'Problem Type' column.\")\n",
        "\n",
        "# Clean problem type\n",
        "df[\"Problem Type\"] = df[\"Problem Type\"].astype(str).str.lower().str.strip()\n",
        "\n",
        "# Identify target column (any column containing 'readmit' or 'readmission')\n",
        "target_candidates = [c for c in df.columns\n",
        "                     if \"readmit\" in c.lower() or \"readmission\" in c.lower()]\n",
        "if not target_candidates:\n",
        "    raise ValueError(\"No readmission target column found.\")\n",
        "target_col = target_candidates[0]\n",
        "\n",
        "# Map target to 0/1\n",
        "df[target_col] = (\n",
        "    df[target_col]\n",
        "    .astype(str).str.lower().str.strip()\n",
        "    .map({\"yes\": 1, \"true\": 1, \"1\": 1, \"no\": 0, \"false\": 0, \"0\": 0})\n",
        "    .fillna(0)\n",
        "    .astype(int)\n",
        ")\n",
        "\n",
        "# ============== SUBSETS ==============\n",
        "df_diabetes = df[df[\"Problem Type\"].str.contains(\"diab\", na=False)]\n",
        "df_heart = df[df[\"Problem Type\"].str.contains(\"heart\", na=False)]\n",
        "\n",
        "print(f\"Diabetes rows: {df_diabetes.shape[0]}\")\n",
        "print(f\"Heart Failure rows: {df_heart.shape[0]}\")\n",
        "\n",
        "if df_diabetes.empty:\n",
        "    raise ValueError(\"No Diabetes records found. Check 'Problem Type' values.\")\n",
        "if df_heart.empty:\n",
        "    raise ValueError(\"No Heart Failure records found. Check 'Problem Type' values.\")\n",
        "\n",
        "# ============== TRAINING FUNCTION ==============\n",
        "def train_for_disease(df_sub: pd.DataFrame, disease_label: str, out_name_suffix: str):\n",
        "    \"\"\"\n",
        "    Trains 3 models (LR, RF, XGB) for a given disease subset.\n",
        "    Uses advanced preprocessing & hyperparameter tuning.\n",
        "    Saves RandomForest as final .pkl.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(f\"üè• TRAINING FOR: {disease_label.upper()}\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    y = df_sub[target_col]\n",
        "    X = df_sub.drop(columns=[target_col, \"Problem Type\"], errors=\"ignore\")\n",
        "\n",
        "    # Identify numeric & categorical columns\n",
        "    num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    cat_cols = X.select_dtypes(include=[\"object\", \"bool\"]).columns.tolist()\n",
        "\n",
        "    # Preprocessor: impute + scale + one-hot\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", Pipeline(steps=[\n",
        "                (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "                (\"scaler\", StandardScaler())\n",
        "            ]), num_cols),\n",
        "            (\"cat\", Pipeline(steps=[\n",
        "                (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "                (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "            ]), cat_cols),\n",
        "        ],\n",
        "        remainder=\"drop\"\n",
        "    )\n",
        "\n",
        "    # Define models\n",
        "    models = {\n",
        "        \"LogisticRegression\": LogisticRegression(\n",
        "            max_iter=4000,\n",
        "            solver=\"liblinear\",\n",
        "            class_weight=\"balanced\",\n",
        "            random_state=RANDOM_STATE,\n",
        "        ),\n",
        "        \"RandomForest\": RandomForestClassifier(\n",
        "            random_state=RANDOM_STATE,\n",
        "            class_weight=\"balanced\",\n",
        "            n_jobs=-1,\n",
        "        ),\n",
        "        \"XGBoost\": XGBClassifier(\n",
        "            random_state=RANDOM_STATE,\n",
        "            eval_metric=\"logloss\",\n",
        "            use_label_encoder=False,\n",
        "            n_jobs=-1,\n",
        "            # handle imbalance\n",
        "            scale_pos_weight=max(\n",
        "                1.0,\n",
        "                float((y == 0).sum()) / max((y == 1).sum(), 1)\n",
        "            ),\n",
        "        ),\n",
        "    }\n",
        "\n",
        "    # Hyperparameter grids (tuned to push AUC/accuracy high)\n",
        "    param_grids = {\n",
        "        \"LogisticRegression\": {\n",
        "            \"clf__C\": [0.01, 0.1, 1, 5, 10],\n",
        "            \"clf__penalty\": [\"l1\", \"l2\"],\n",
        "        },\n",
        "        \"RandomForest\": {\n",
        "            \"clf__n_estimators\": [200, 400, 600],\n",
        "            \"clf__max_depth\": [10, 15, 20, None],\n",
        "            \"clf__min_samples_split\": [2, 4],\n",
        "            \"clf__min_samples_leaf\": [1, 2],\n",
        "            \"clf__max_features\": [\"sqrt\", \"log2\"],\n",
        "        },\n",
        "        \"XGBoost\": {\n",
        "            \"clf__learning_rate\": [0.01, 0.05, 0.1],\n",
        "            \"clf__max_depth\": [3, 5, 7],\n",
        "            \"clf__n_estimators\": [150, 250, 350],\n",
        "            \"clf__subsample\": [0.8, 1.0],\n",
        "            \"clf__colsample_bytree\": [0.8, 1.0],\n",
        "        },\n",
        "    }\n",
        "\n",
        "    # Train/val split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y,\n",
        "        test_size=TEST_SIZE,\n",
        "        stratify=y,\n",
        "        random_state=RANDOM_STATE\n",
        "    )\n",
        "\n",
        "    cv = StratifiedKFold(\n",
        "        n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE\n",
        "    )\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for name, base_clf in models.items():\n",
        "        print(\"\\n\" + \"-\" * 50)\n",
        "        print(f\"üîπ {disease_label} - {name}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        pipe = Pipeline(steps=[\n",
        "            (\"pre\", preprocessor),\n",
        "            (\"clf\", base_clf),\n",
        "        ])\n",
        "\n",
        "        grid = GridSearchCV(\n",
        "            estimator=pipe,\n",
        "            param_grid=param_grids[name],\n",
        "            scoring=\"roc_auc\",\n",
        "            n_jobs=-1,\n",
        "            cv=cv,\n",
        "            verbose=1,\n",
        "        )\n",
        "        grid.fit(X_train, y_train)\n",
        "\n",
        "        best = grid.best_estimator_\n",
        "        y_pred = best.predict(X_test)\n",
        "        y_prob = best.predict_proba(X_test)[:, 1]\n",
        "\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "        prec = precision_score(y_test, y_pred)\n",
        "        rec = recall_score(y_test, y_pred)\n",
        "        auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "        print(f\"Best Params: {grid.best_params_}\")\n",
        "        print(f\"Accuracy:      {acc:.4f}\")\n",
        "        print(f\"Precision:     {prec:.4f}\")\n",
        "        print(f\"Recall:        {rec:.4f}\")\n",
        "        print(f\"F1 Score:      {f1:.4f}\")\n",
        "        print(f\"ROC-AUC:       {auc:.4f}\")\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "        results.append({\n",
        "            \"Model\": name,\n",
        "            \"Estimator\": best,\n",
        "            \"Accuracy\": acc,\n",
        "            \"F1\": f1,\n",
        "            \"AUC\": auc,\n",
        "        })\n",
        "\n",
        "    # Summarize results\n",
        "    results_df = pd.DataFrame(results).sort_values(by=[\"AUC\", \"Accuracy\"], ascending=False)\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(f\"üìä SUMMARY - {disease_label}\")\n",
        "    print(results_df[[\"Model\", \"Accuracy\", \"F1\", \"AUC\"]])\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # ----- Select Random Forest as final model -----\n",
        "    # Check if RandomForest is in results before trying to access it\n",
        "    rf_row = next((r for r in results if r[\"Model\"] == \"RandomForest\"), None)\n",
        "\n",
        "    if rf_row:\n",
        "        rf_acc = rf_row[\"Accuracy\"]\n",
        "        rf_auc = rf_row[\"AUC\"]\n",
        "\n",
        "        if rf_acc < 0.80:\n",
        "            print(f\"\\n Warning: RandomForest accuracy for {disease_label} is {rf_acc:.2%} (< 80%).\")\n",
        "            print(\"   Tune data/labels or features if you must strictly exceed 80%.\")\n",
        "        else:\n",
        "            print(f\"\\n‚úÖ RandomForest for {disease_label} achieved {rf_acc:.2%} accuracy (AUC={rf_auc:.3f}).\")\n",
        "\n",
        "        final_model = rf_row[\"Estimator\"]\n",
        "        out_path = f\"readmission_{out_name_suffix}_RandomForest.pkl\"\n",
        "        joblib.dump(final_model, out_path)\n",
        "        print(f\"Saved RandomForest model for {disease_label} -> {out_path}\")\n",
        "    else:\n",
        "        print(f\"\\n Warning: RandomForest model not found in results for {disease_label}. Skipping save.\")\n",
        "\n",
        "\n",
        "    return results_df\n",
        "\n",
        "# ============== RUN TRAINING FOR BOTH ==============\n",
        "diab_results = train_for_disease(df_diabetes, \"Diabetes\", \"diabetes\")\n",
        "heart_results = train_for_disease(df_heart, \"Heart Failure\", \"heart_failure\")\n",
        "\n",
        "print(\"\\n================= ALL DONE =================\")\n",
        "print(\"Diabetes models summary:\")\n",
        "print(diab_results)\n",
        "print(\"\\nHeart Failure models summary:\")\n",
        "print(heart_results)\n",
        "print(\"RandomForest PKL files are ready for your Flask app.\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diabetes rows: 2488\n",
            "Heart Failure rows: 2512\n",
            "\n",
            "======================================================================\n",
            "üè• TRAINING FOR: DIABETES\n",
            "======================================================================\n",
            "\n",
            "--------------------------------------------------\n",
            "üîπ Diabetes - LogisticRegression\n",
            "--------------------------------------------------\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "Best Params: {'clf__C': 0.1, 'clf__penalty': 'l1'}\n",
            "Accuracy:      0.6325\n",
            "Precision:     0.5023\n",
            "Recall:        0.6033\n",
            "F1 Score:      0.5481\n",
            "ROC-AUC:       0.6751\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.65      0.69       314\n",
            "           1       0.50      0.60      0.55       184\n",
            "\n",
            "    accuracy                           0.63       498\n",
            "   macro avg       0.62      0.63      0.62       498\n",
            "weighted avg       0.65      0.63      0.64       498\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "üîπ Diabetes - RandomForest\n",
            "--------------------------------------------------\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "Best Params: {'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 4, 'clf__n_estimators': 600}\n",
            "Accuracy:      0.6466\n",
            "Precision:     0.6667\n",
            "Recall:        0.0870\n",
            "F1 Score:      0.1538\n",
            "ROC-AUC:       0.6680\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.97      0.78       314\n",
            "           1       0.67      0.09      0.15       184\n",
            "\n",
            "    accuracy                           0.65       498\n",
            "   macro avg       0.66      0.53      0.47       498\n",
            "weighted avg       0.65      0.65      0.55       498\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "üîπ Diabetes - XGBoost\n",
            "--------------------------------------------------\n",
            "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
            "Best Params: {'clf__colsample_bytree': 1.0, 'clf__learning_rate': 0.05, 'clf__max_depth': 3, 'clf__n_estimators': 150, 'clf__subsample': 0.8}\n",
            "Accuracy:      0.6446\n",
            "Precision:     0.5158\n",
            "Recall:        0.6196\n",
            "F1 Score:      0.5630\n",
            "ROC-AUC:       0.6666\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.66      0.70       314\n",
            "           1       0.52      0.62      0.56       184\n",
            "\n",
            "    accuracy                           0.64       498\n",
            "   macro avg       0.63      0.64      0.63       498\n",
            "weighted avg       0.66      0.64      0.65       498\n",
            "\n",
            "\n",
            "==================================================\n",
            "üìä SUMMARY - Diabetes\n",
            "                Model  Accuracy        F1       AUC\n",
            "0  LogisticRegression  0.632530  0.548148  0.675142\n",
            "1        RandomForest  0.646586  0.153846  0.668046\n",
            "2             XGBoost  0.644578  0.562963  0.666592\n",
            "==================================================\n",
            "\n",
            " Warning: RandomForest accuracy for Diabetes is 64.66% (< 80%).\n",
            "   Tune data/labels or features if you must strictly exceed 80%.\n",
            "Saved RandomForest model for Diabetes -> readmission_diabetes_RandomForest.pkl\n",
            "\n",
            "======================================================================\n",
            "üè• TRAINING FOR: HEART FAILURE\n",
            "======================================================================\n",
            "\n",
            "--------------------------------------------------\n",
            "üîπ Heart Failure - LogisticRegression\n",
            "--------------------------------------------------\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "Best Params: {'clf__C': 0.1, 'clf__penalty': 'l1'}\n",
            "Accuracy:      0.6243\n",
            "Precision:     0.4686\n",
            "Recall:        0.6437\n",
            "F1 Score:      0.5424\n",
            "ROC-AUC:       0.6951\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.61      0.68       329\n",
            "           1       0.47      0.64      0.54       174\n",
            "\n",
            "    accuracy                           0.62       503\n",
            "   macro avg       0.62      0.63      0.61       503\n",
            "weighted avg       0.66      0.62      0.63       503\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "üîπ Heart Failure - RandomForest\n",
            "--------------------------------------------------\n",
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "Best Params: {'clf__max_depth': 15, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__n_estimators': 200}\n",
            "Accuracy:      0.6620\n",
            "Precision:     0.5196\n",
            "Recall:        0.3046\n",
            "F1 Score:      0.3841\n",
            "ROC-AUC:       0.6399\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.85      0.77       329\n",
            "           1       0.52      0.30      0.38       174\n",
            "\n",
            "    accuracy                           0.66       503\n",
            "   macro avg       0.61      0.58      0.58       503\n",
            "weighted avg       0.64      0.66      0.63       503\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "üîπ Heart Failure - XGBoost\n",
            "--------------------------------------------------\n",
            "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
            "Best Params: {'clf__colsample_bytree': 0.8, 'clf__learning_rate': 0.01, 'clf__max_depth': 3, 'clf__n_estimators': 150, 'clf__subsample': 0.8}\n",
            "Accuracy:      0.6302\n",
            "Precision:     0.4730\n",
            "Recall:        0.6034\n",
            "F1 Score:      0.5303\n",
            "ROC-AUC:       0.6773\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.64      0.70       329\n",
            "           1       0.47      0.60      0.53       174\n",
            "\n",
            "    accuracy                           0.63       503\n",
            "   macro avg       0.61      0.62      0.61       503\n",
            "weighted avg       0.66      0.63      0.64       503\n",
            "\n",
            "\n",
            "==================================================\n",
            "üìä SUMMARY - Heart Failure\n",
            "                Model  Accuracy        F1       AUC\n",
            "0  LogisticRegression  0.624254  0.542373  0.695053\n",
            "2             XGBoost  0.630219  0.530303  0.677322\n",
            "1        RandomForest  0.662028  0.384058  0.639940\n",
            "==================================================\n",
            "\n",
            " Warning: RandomForest accuracy for Heart Failure is 66.20% (< 80%).\n",
            "   Tune data/labels or features if you must strictly exceed 80%.\n",
            "Saved RandomForest model for Heart Failure -> readmission_heart_failure_RandomForest.pkl\n",
            "\n",
            "================= ALL DONE =================\n",
            "Diabetes models summary:\n",
            "                Model                                          Estimator  \\\n",
            "0  LogisticRegression  (ColumnTransformer(transformers=[('num',\\n    ...   \n",
            "1        RandomForest  (ColumnTransformer(transformers=[('num',\\n    ...   \n",
            "2             XGBoost  (ColumnTransformer(transformers=[('num',\\n    ...   \n",
            "\n",
            "   Accuracy        F1       AUC  \n",
            "0  0.632530  0.548148  0.675142  \n",
            "1  0.646586  0.153846  0.668046  \n",
            "2  0.644578  0.562963  0.666592  \n",
            "\n",
            "Heart Failure models summary:\n",
            "                Model                                          Estimator  \\\n",
            "0  LogisticRegression  (ColumnTransformer(transformers=[('num',\\n    ...   \n",
            "2             XGBoost  (ColumnTransformer(transformers=[('num',\\n    ...   \n",
            "1        RandomForest  (ColumnTransformer(transformers=[('num',\\n    ...   \n",
            "\n",
            "   Accuracy        F1       AUC  \n",
            "0  0.624254  0.542373  0.695053  \n",
            "2  0.630219  0.530303  0.677322  \n",
            "1  0.662028  0.384058  0.639940  \n",
            "RandomForest PKL files are ready for your Flask app.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77104a9d",
        "outputId": "f68f9634-5998-49dd-d2c0-036b69da1be5"
      },
      "source": [
        "!pip install xgboost"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xgboost\n",
            "  Downloading xgboost-3.1.1-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.0.2)\n",
            "Collecting nvidia-nccl-cu12 (from xgboost)\n",
            "  Downloading nvidia_nccl_cu12-2.28.7-py3-none-manylinux_2_18_x86_64.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.3)\n",
            "Downloading xgboost-3.1.1-py3-none-manylinux_2_28_x86_64.whl (115.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m115.9/115.9 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.28.7-py3-none-manylinux_2_18_x86_64.whl (296.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m296.8/296.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nccl-cu12, xgboost\n",
            "Successfully installed nvidia-nccl-cu12-2.28.7 xgboost-3.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL SELECTION"
      ],
      "metadata": {
        "id": "9NJmEUDJfsXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Model selection by ROC-AUC ---\")\n",
        "\n",
        "# Combine the results from both training runs into the results dictionary\n",
        "results = {}\n",
        "for index, row in diab_results.iterrows():\n",
        "    # Include all relevant metrics from the results DataFrames\n",
        "    results[row['Model'] + \"_Diabetes\"] = {\n",
        "        'roc_auc': row['AUC'],\n",
        "        'accuracy': row['Accuracy'],\n",
        "        'f1': row['F1'],\n",
        "        'precision': None, # Precision is not directly available in diab_results summary, will need re-evaluation or storing more metrics\n",
        "        'recall': None,    # Recall is not directly available\n",
        "        'pr_auc': None     # PR-AUC is not directly available\n",
        "    }\n",
        "for index, row in heart_results.iterrows():\n",
        "    # Include all relevant metrics from the results DataFrames\n",
        "     results[row['Model'] + \"_HeartFailure\"] = {\n",
        "        'roc_auc': row['AUC'],\n",
        "        'accuracy': row['Accuracy'],\n",
        "        'f1': row['F1'],\n",
        "        'precision': None, # Precision is not directly available in heart_results summary\n",
        "        'recall': None,    # Recall is not directly available\n",
        "        'pr_auc': None     # PR-AUC is not directly available\n",
        "    }\n",
        "\n",
        "# --- FIX: Re-evaluate the best model on the test set to get all metrics for the summary ---\n",
        "# Get the best pipeline (already done in cell u-mG2H9RfPCm and used in 5onZPExzgdqN)\n",
        "# Assuming new_pipeline (trained on full X_train) is the one we want to summarize metrics for on X_test\n",
        "if 'new_pipeline' in locals(): # Check if new_pipeline exists from previous execution\n",
        "    print(f\"Evaluating the retrained pipeline ({best_name.split('_')[0]} on full data) on X_test for summary metrics...\")\n",
        "    y_prob_test_summary = new_pipeline.predict_proba(X_test)[:,1]\n",
        "    y_pred_test_summary = (y_prob_test_summary >= RISK_THRESHOLD).astype(int)\n",
        "\n",
        "    # Update the results dictionary for the selected best model with metrics from the evaluation on X_test\n",
        "    # Note: This assumes the best_name corresponds to the model structure in new_pipeline\n",
        "    # This is a simplification, ideally, we'd store full metrics during the grid search\n",
        "    # or re-evaluate the specific best model from diab_results/heart_results on its subset test set.\n",
        "    # Given the flow, summarizing the 'new_pipeline' (best structure on full data) on X_test is most practical.\n",
        "    if best_name in results:\n",
        "         results[best_name]['roc_auc'] = roc_auc_score(y_test, y_prob_test_summary)\n",
        "         results[best_name]['pr_auc'] = average_precision_score(y_test, y_prob_test_summary)\n",
        "         results[best_name]['accuracy'] = accuracy_score(y_test, y_pred_test_summary)\n",
        "         results[best_name]['precision'] = precision_score(y_test, y_pred_test_summary, zero_division=0)\n",
        "         results[best_name]['recall'] = recall_score(y_test, y_pred_test_summary, zero_division=0)\n",
        "         results[best_name]['f1'] = f1_score(y_test, y_pred_test_summary, zero_division=0)\n",
        "         # Confusion matrix is not easily stored in this summary structure, skipping\n",
        "\n",
        "    print(\"Updated summary metrics for:\", best_name)\n",
        "else:\n",
        "    print(\"Warning: new_pipeline not found. Summary metrics in JSON might be incomplete.\")\n",
        "# --- End of FIX ---\n",
        "\n",
        "\n",
        "best_name = max(results.items(), key=lambda kv: kv[1]['roc_auc'])[0]\n",
        "print(\"Model scores (ROC-AUC):\")\n",
        "for k,v in results.items():\n",
        "    # Print available metrics\n",
        "    metrics_str = f\"ROC-AUC={v.get('roc_auc', 'N/A'):.4f}\"\n",
        "    if v.get('accuracy') is not None: metrics_str += f\", Acc={v['accuracy']:.4f}\"\n",
        "    if v.get('f1') is not None: metrics_str += f\", F1={v['f1']:.4f}\"\n",
        "    if v.get('precision') is not None: metrics_str += f\", Prec={v['precision']:.4f}\"\n",
        "    if v.get('recall') is not None: metrics_str += f\", Rec={v['recall']:.4f}\"\n",
        "    if v.get('pr_auc') is not None: metrics_str += f\", PR-AUC={v['pr_auc']:.4f}\"\n",
        "    print(f\" - {k}: {metrics_str}\")\n",
        "\n",
        "print(\"Selected best model:\", best_name)\n",
        "\n",
        "# This part of the code needs to be adjusted based on how 'best_pipeline' is intended to be used.\n",
        "# The previous training cell saved individual models for Diabetes and Heart Failure.\n",
        "# This cell was originally set up to select one best pipeline from a single training run.\n",
        "# Since we trained two separate models (RF for Diabetes and RF for Heart Failure),\n",
        "# the concept of a single \"best_pipeline\" for the entire dataset might not be appropriate here.\n",
        "# If the goal is to select the single best *Random Forest* model across both diseases,\n",
        "# we would need to determine which one had a higher ROC-AUC during its specific training run.\n",
        "\n",
        "# For now, let's assume we want to select the overall best model based on ROC-AUC from the combined results\n",
        "# However, remember these AUCs are from separate test sets (Diabetes test set and Heart Failure test set).\n",
        "# A more robust approach would be to evaluate ALL trained models (LR, RF, XGB for both diseases)\n",
        "# on the full test set X_test from the original split, after applying the appropriate preprocessing.\n",
        "\n",
        "# Given the current structure, the original logic of selecting a single best_pipeline based on the 'results' dictionary\n",
        "# does not align with the two separate saved models.\n",
        "\n",
        "# I will comment out the saving part for now as it requires a decision on which model to save as \"best\".\n",
        "# best_model_path = os.path.join(OUTPUT_DIR, \"best_readmission_pipeline.joblib\")\n",
        "# joblib.dump(best_pipeline, best_model_path)\n",
        "# print(\"Saved best pipeline to:\", best_model_path)\n",
        "\n",
        "# Note: The downstream cells (Explanaibility, Score Full Data, Plot ROC/PR, Interpretible Risk Mapping)\n",
        "# will also need to be adapted to work with either the separate disease-specific models,\n",
        "# or by selecting and loading one of the saved models (e.g., the best overall performing one or a specific one like RF for Diabetes)."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDTFzsIAfrP9",
        "outputId": "9e82fdfd-3ca3-4c9b-f0bd-70d014000e49"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model selection by ROC-AUC ---\n",
            "Evaluating the retrained pipeline (LogisticRegression on full data) on X_test for summary metrics...\n",
            "Updated summary metrics for: LogisticRegression_HeartFailure\n",
            "Model scores (ROC-AUC):\n",
            " - LogisticRegression_Diabetes: ROC-AUC=0.6751, Acc=0.6325, F1=0.5481\n",
            " - RandomForest_Diabetes: ROC-AUC=0.6680, Acc=0.6466, F1=0.1538\n",
            " - XGBoost_Diabetes: ROC-AUC=0.6666, Acc=0.6446, F1=0.5630\n",
            " - LogisticRegression_HeartFailure: ROC-AUC=0.6398, Acc=0.6050, F1=0.4981, Prec=0.4569, Rec=0.5475, PR-AUC=0.5036\n",
            " - XGBoost_HeartFailure: ROC-AUC=0.6773, Acc=0.6302, F1=0.5303\n",
            " - RandomForest_HeartFailure: ROC-AUC=0.6399, Acc=0.6620, F1=0.3841\n",
            "Selected best model: XGBoost_HeartFailure\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPLANABILITY"
      ],
      "metadata": {
        "id": "6siaEar3gDGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nComputing feature names (post-preprocessing)...\")\n",
        "\n",
        "# --- FIX: Retrieve the best pipeline based on best_name ---\n",
        "# Find the best model's estimator from the results DataFrames\n",
        "best_pipeline = None\n",
        "model_name, disease_suffix = best_name.rsplit('_', 1) # Split 'LogisticRegression_HeartFailure' into 'LogisticRegression' and 'HeartFailure'\n",
        "\n",
        "if disease_suffix == 'Diabetes':\n",
        "    best_row = diab_results[diab_results['Model'] == model_name]\n",
        "    if not best_row.empty:\n",
        "        best_pipeline = best_row.iloc[0]['Estimator']\n",
        "elif disease_suffix == 'HeartFailure':\n",
        "    best_row = heart_results[heart_results['Model'] == model_name]\n",
        "    if not best_row.empty:\n",
        "        best_pipeline = best_row.iloc[0]['Estimator']\n",
        "\n",
        "if best_pipeline is None:\n",
        "    raise RuntimeError(f\"Could not find the estimator for the best model: {best_name}\")\n",
        "# --- End of FIX ---\n",
        "\n",
        "\n",
        "# try to reconstruct feature names\n",
        "feature_names = []\n",
        "try:\n",
        "    pre = best_pipeline.named_steps['pre']\n",
        "    # ColumnTransformer.get_feature_names_out is available on modern sklearn\n",
        "    try:\n",
        "        feature_names = pre.get_feature_names_out()\n",
        "    except Exception:\n",
        "        # attempt manual concatenation\n",
        "        # Need to get the correct original columns used by the preprocessor\n",
        "        # This is tricky as the original X varies by disease subset\n",
        "        # A safer approach might be to fit the preprocessor on the full X_train\n",
        "        # and then use its get_feature_names_out.\n",
        "        # For now, let's try to get the columns from the preprocessor pipeline steps if possible\n",
        "        num_cols_processed = pre.transformers_[0][2] if len(pre.transformers_) > 0 and pre.transformers_[0][0] == 'num' else []\n",
        "        cat_cols_processed = pre.transformers_[1][2] if len(pre.transformers_) > 1 and pre.transformers_[1][0] == 'cat' else []\n",
        "\n",
        "        cat_encoder = pre.named_transformers_['cat'].named_steps['onehot'] if 'cat' in pre.named_transformers_ else None\n",
        "        if cat_encoder is not None:\n",
        "            # Use cat_cols_processed which are the original column names passed to the categorical transformer\n",
        "            cat_names = cat_encoder.get_feature_names_out(cat_cols_processed)\n",
        "            feature_names = list(num_cols_processed) + list(cat_names)\n",
        "        else:\n",
        "            feature_names = list(num_cols_processed) + list(cat_cols_processed) # Fallback if onehot is not found\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"Could not extract feature names automatically:\", e)\n",
        "    # Fallback to original columns if feature name extraction fails\n",
        "    # Note: This will not match the post-preprocessing features but prevents error\n",
        "    feature_names = list(X.columns)\n",
        "\n",
        "\n",
        "# Feature importances for tree models\n",
        "clf = best_pipeline.named_steps.get('clf', None)\n",
        "if hasattr(clf, \"feature_importances_\"):\n",
        "    try:\n",
        "        importances = clf.feature_importances_\n",
        "        # align length\n",
        "        if len(feature_names) == len(importances):\n",
        "             imp_df = pd.DataFrame({'feature': feature_names, 'importance': importances}).sort_values('importance', ascending=False)\n",
        "             imp_df.to_csv(os.path.join(OUTPUT_DIR, \"feature_importances.csv\"), index=False)\n",
        "             print(\"Saved feature importances to output directory.\")\n",
        "        else:\n",
        "            print(f\"Feature names count ({len(feature_names)}) does not match importances count ({len(importances)}); skipping importance save.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Could not produce feature importances:\", e)\n",
        "elif hasattr(clf, \"coef_\"):\n",
        "     # For linear models like Logistic Regression, use coefficients\n",
        "     try:\n",
        "        coefs = clf.coef_[0] if clf.coef_.ndim > 1 else clf.coef_\n",
        "        # Ensure feature_names length matches coefficients length\n",
        "        if len(feature_names) == len(coefs):\n",
        "            coef_df = pd.DataFrame({'feature': feature_names, 'coefficient': coefs}).sort_values('coefficient', ascending=False)\n",
        "            coef_df.to_csv(os.path.join(OUTPUT_DIR, \"feature_coefficients.csv\"), index=False)\n",
        "            print(\"Saved feature coefficients to output directory.\")\n",
        "        else:\n",
        "             print(f\"Feature names count ({len(feature_names)}) does not match coefficients count ({len(coefs)}); skipping coefficient save.\")\n",
        "\n",
        "     except Exception as e:\n",
        "        print(\"Could not produce feature coefficients:\", e)\n",
        "\n",
        "else:\n",
        "    print(\"Best model does not expose feature_importances_ or coef_.\")\n",
        "\n",
        "# SHAP explanations (if available)\n",
        "if SHAP_AVAILABLE:\n",
        "    try:\n",
        "        print(\"Computing SHAP values (sample) ‚Äî this can take time...\")\n",
        "        # generate background by sampling training set after preprocessing\n",
        "        # Use best_pipeline to transform\n",
        "        preproc = best_pipeline.named_steps['pre']\n",
        "        # Take a small background from the relevant training set subset\n",
        "        if disease_suffix == 'Diabetes':\n",
        "            X_train_subset = X_train[X_train['Problem Type'].str.contains(\"diab\", na=False)].drop(columns=[\"Problem Type\"], errors=\"ignore\")\n",
        "        elif disease_suffix == 'HeartFailure':\n",
        "             X_train_subset = X_train[X_train['Problem Type'].str.contains(\"heart\", na=False)].drop(columns=[\"Problem Type\"], errors=\"ignore\")\n",
        "        else:\n",
        "             X_train_subset = X_train.drop(columns=[\"Problem Type\"], errors=\"ignore\") # Fallback to full X_train if disease is unknown\n",
        "\n",
        "        if not X_train_subset.empty:\n",
        "            bg = X_train_subset.sample(min(200, len(X_train_subset)), random_state=RANDOM_STATE)\n",
        "            X_bg = preproc.transform(bg)\n",
        "\n",
        "            # Prepare sample for SHAP from the relevant test set subset\n",
        "            if disease_suffix == 'Diabetes':\n",
        "                X_test_subset = X_test[X_test['Problem Type'].str.contains(\"diab\", na=False)].drop(columns=[\"Problem Type\"], errors=\"ignore\")\n",
        "            elif disease_suffix == 'HeartFailure':\n",
        "                 X_test_subset = X_test[X_test['Problem Type'].str.contains(\"heart\", na=False)].drop(columns=[\"Problem Type\"], errors=\"ignore\")\n",
        "            else:\n",
        "                 X_test_subset = X_test.drop(columns=[\"Problem Type\"], errors=\"ignore\") # Fallback to full X_test if disease is unknown\n",
        "\n",
        "            if not X_test_subset.empty:\n",
        "                sample_for_shap_df = X_test_subset.sample(min(100, len(X_test_subset)), random_state=RANDOM_STATE)\n",
        "                sample_for_shap = preproc.transform(sample_for_shap_df)\n",
        "\n",
        "                # create shap explainer for estimator\n",
        "                explainer = shap.Explainer(best_pipeline.named_steps['clf'], X_bg, feature_names=feature_names)\n",
        "                shap_vals = explainer(sample_for_shap)\n",
        "                # save summary plot\n",
        "                shap.summary_plot(shap_vals, feature_names=feature_names, show=False)\n",
        "                plt.savefig(os.path.join(OUTPUT_DIR, f\"shap_summary_{disease_suffix}.png\"), bbox_inches='tight')\n",
        "                plt.close()\n",
        "                print(f\"Saved SHAP summary plot for {disease_suffix}.\")\n",
        "            else:\n",
        "                 print(f\"Test subset for {disease_suffix} is empty; skipping SHAP for this subset.\")\n",
        "        else:\n",
        "            print(f\"Train subset for {disease_suffix} is empty; skipping SHAP for this subset.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"SHAP failed:\", e)\n",
        "else:\n",
        "    print(\"SHAP not installed; skip SHAP analysis.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-mG2H9RfPCm",
        "outputId": "77216b79-a5f8-4ed1-a18c-288638683ac5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Computing feature names (post-preprocessing)...\n",
            "Saved feature coefficients to output directory.\n",
            "SHAP not installed; skip SHAP analysis.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SCORE FULL DATA"
      ],
      "metadata": {
        "id": "9rf7KSlVgOby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nScoring full dataset and saving predictions...\")\n",
        "X_full = X.copy()\n",
        "\n",
        "# --- FIX: Create a new pipeline with a preprocessor configured for full data and train on X_train ---\n",
        "\n",
        "# 1. Get the best classifier's type and hyperparameters from the best_pipeline\n",
        "best_classifier_type = type(best_pipeline.named_steps['clf'])\n",
        "best_classifier_params = best_pipeline.named_steps['clf'].get_params()\n",
        "\n",
        "# 2. Create a new preprocessor configured for the full dataset using numeric_cols and cat_cols\n",
        "# These variables were defined in cell eORIP4-VHQcG and should be available.\n",
        "full_data_preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='median')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ]), numeric_cols), # Use numeric_cols from the full dataset analysis\n",
        "    ('cat', Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ]), cat_cols) # Use cat_cols from the full dataset analysis\n",
        "], remainder='drop', sparse_threshold=0)\n",
        "\n",
        "# 3. Create a new pipeline with the full data preprocessor and the best classifier\n",
        "new_pipeline = Pipeline(steps=[\n",
        "    ('pre', full_data_preprocessor),\n",
        "    ('clf', best_classifier_type(**best_classifier_params)) # Instantiate the best classifier with its params\n",
        "])\n",
        "\n",
        "# 4. Fit this new pipeline on the original full training data (X_train, y_train)\n",
        "print(f\"Fitting a new pipeline with the best classifier structure ({best_name.split('_')[0]}) on the full training data (X_train, y_train)...\")\n",
        "new_pipeline.fit(X_train, y_train)\n",
        "print(\"Fitting complete.\")\n",
        "\n",
        "# 5. Use this newly fitted pipeline to predict on the full X_full data\n",
        "pred_probs = new_pipeline.predict_proba(X_full)[:,1]\n",
        "# --- End of FIX ---\n",
        "\n",
        "df_out = df_fe.copy()\n",
        "df_out['Predicted_Risk_Score'] = pred_probs\n",
        "df_out['Predicted_Readmission'] = np.where(df_out['Predicted_Risk_Score'] >= RISK_THRESHOLD, 'Yes', 'No')\n",
        "\n",
        "out_csv = os.path.join(OUTPUT_DIR, \"readmission_predictions_with_features.csv\")\n",
        "df_out.to_csv(out_csv, index=False)\n",
        "print(\"Saved predictions CSV to:\", out_csv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UB2qbX7ngQnc",
        "outputId": "6794ec57-27fc-4f10-9869-287681b404a9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Scoring full dataset and saving predictions...\n",
            "Fitting a new pipeline with the best classifier structure (LogisticRegression) on the full training data (X_train, y_train)...\n",
            "Fitting complete.\n",
            "Saved predictions CSV to: /content/drive/MyDrive/readmission_output.csv/readmission_predictions_with_features.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PLOT ROC AND PR CURVES"
      ],
      "metadata": {
        "id": "9LuIx-2egeWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Plotting ROC and PR curves for best model on test set...\")\n",
        "# --- FIX: Use the new_pipeline (trained on full X_train) to predict on X_test ---\n",
        "# The new_pipeline was created and fitted in the previous cell (UB2qbX7ngQnc)\n",
        "# Assuming new_pipeline is available from the previous execution\n",
        "\n",
        "y_prob_test = new_pipeline.predict_proba(X_test)[:,1]\n",
        "# --- End of FIX ---\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob_test)\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_prob_test)\n",
        "roc_auc_val = roc_auc_score(y_test, y_prob_test)\n",
        "pr_auc_val = average_precision_score(y_test, y_prob_test)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.plot(fpr, tpr, label=f'ROC (AUC={roc_auc_val:.3f})')\n",
        "plt.plot([0,1],[0,1],'--', color='gray')\n",
        "plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate'); plt.title('ROC Curve'); plt.legend(); plt.grid(True)\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, \"roc_curve.png\"))\n",
        "plt.close()\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.plot(recall, precision, label=f'PR (AUC={pr_auc_val:.3f})')\n",
        "plt.xlabel('Recall'); plt.ylabel('Precision'); plt.title('Precision-Recall Curve'); plt.legend(); plt.grid(True)\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, \"pr_curve.png\"))\n",
        "plt.close()\n",
        "\n",
        "print(\"Saved ROC and PR plots to output directory.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5onZPExzgdqN",
        "outputId": "64c0e3c0-7cd2-43fd-dac7-8d0f6c8ec813"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting ROC and PR curves for best model on test set...\n",
            "Saved ROC and PR plots to output directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CREATE INTERPRETABLE RISK SCORING SYSTEM MAPPING"
      ],
      "metadata": {
        "id": "OmyH_QzZgzup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def risk_group(score):\n",
        "    if score > 0.7:\n",
        "        return \"HIGH\"\n",
        "    if score > 0.3:\n",
        "        return \"MODERATE\"\n",
        "    return \"LOW\"\n",
        "\n",
        "df_out['RiskGroup'] = df_out['Predicted_Risk_Score'].apply(risk_group)\n",
        "df_out.to_csv(out_csv, index=False)  # overwrite with risk group included\n",
        "print(\"Added RiskGroup and updated CSV:\", out_csv)\n",
        "\n",
        "# Save a JSON summary of metrics\n",
        "# --- FIX: Use metrics from the evaluation of new_pipeline on X_test ---\n",
        "# Assuming roc_auc_val, pr_auc_val, and other metrics from evaluating new_pipeline on X_test\n",
        "# are available from previous cell execution (e.g., cell 5onZPExzgdqN)\n",
        "# We also need accuracy, precision, recall, and f1 from that evaluation.\n",
        "# Since new_pipeline was evaluated on X_test in cell 5onZPExzgdqN, we can re-calculate\n",
        "# the classification metrics here using y_test and predictions from new_pipeline.\n",
        "# Alternatively, ensure the evaluation in cell 5onZPExzgdqN saves these metrics to variables.\n",
        "# Let's assume y_test and new_pipeline are available and re-calculate here for robustness.\n",
        "\n",
        "if 'new_pipeline' in locals() and 'y_test' in locals():\n",
        "    # FIX: Pass X_test instead of y_test.index to predict_proba\n",
        "    y_prob_test_for_summary = new_pipeline.predict_proba(X_test)[:, 1]\n",
        "    y_pred_test_for_summary = (y_prob_test_for_summary >= RISK_THRESHOLD).astype(int)\n",
        "\n",
        "    summary = {\n",
        "        'best_model': best_name,\n",
        "        'metrics_test': {\n",
        "            'roc_auc': roc_auc_score(y_test, y_prob_test_for_summary),\n",
        "            'pr_auc': average_precision_score(y_test, y_prob_test_for_summary),\n",
        "            'accuracy': accuracy_score(y_test, y_pred_test_for_summary),\n",
        "            'precision': precision_score(y_test, y_pred_test_for_summary, zero_division=0),\n",
        "            'recall': recall_score(y_test, y_pred_test_for_summary, zero_division=0),\n",
        "            'f1': f1_score(y_test, y_pred_test_for_summary, zero_division=0)\n",
        "        },\n",
        "        'timestamp': datetime.utcnow().isoformat()\n",
        "    }\n",
        "    print(\"Populated summary metrics using new_pipeline evaluation on X_test.\")\n",
        "else:\n",
        "     # Fallback if new_pipeline or y_test are not available (shouldn't happen with current flow)\n",
        "     summary = {\n",
        "        'best_model': best_name,\n",
        "        'metrics_test': {\n",
        "            'roc_auc': results[best_name].get('roc_auc'),\n",
        "            'pr_auc': results[best_name].get('pr_auc'),\n",
        "            'accuracy': results[best_name].get('accuracy'),\n",
        "            'precision': results[best_name].get('precision'),\n",
        "            'recall': results[best_name].get('recall'),\n",
        "            'f1': results[best_name].get('f1')\n",
        "        },\n",
        "        'timestamp': datetime.utcnow().isoformat()\n",
        "    }\n",
        "     print(\"Warning: new_pipeline or y_test not found. Populating summary from potentially incomplete results dict.\")\n",
        "\n",
        "# --- End of FIX ---\n",
        "\n",
        "with open(os.path.join(OUTPUT_DIR, \"training_summary.json\"), \"w\") as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "\n",
        "print(\"\\nAll done. Artifacts written to:\", OUTPUT_DIR)\n",
        "# Safely print metrics from the summary dictionary\n",
        "print(\"Best model:\", summary.get('best_model'))\n",
        "metrics = summary.get('metrics_test', {})\n",
        "print(f\"Metrics (Test Set): ROC-AUC={metrics.get('roc_auc', 'N/A'):.4f}, PR-AUC={metrics.get('pr_auc', 'N/A'):.4f}, Acc={metrics.get('accuracy', 'N/A'):.4f}, F1={metrics.get('f1', 'N/A'):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_NU7O-TgzBe",
        "outputId": "8a9c150a-bf2f-42c7-8d25-9c5f75ec5f4e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added RiskGroup and updated CSV: /content/drive/MyDrive/readmission_output.csv/readmission_predictions_with_features.csv\n",
            "Populated summary metrics using new_pipeline evaluation on X_test.\n",
            "\n",
            "All done. Artifacts written to: /content/drive/MyDrive/readmission_output.csv\n",
            "Best model: XGBoost_HeartFailure\n",
            "Metrics (Test Set): ROC-AUC=0.6398, PR-AUC=0.5036, Acc=0.6050, F1=0.4981\n"
          ]
        }
      ]
    }
  ]
}